package test

import (
	"crypto/md5"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"time"

	"kiro2api/parser"
	"kiro2api/utils"
)

// HexDataAnalyzer åå…­è¿›åˆ¶æ•°æ®è§£æå™¨
type HexDataAnalyzer struct {
	rawDataRecord *utils.RawDataRecord
	logger        utils.Logger
}

// ParsedHexData è§£æåçš„åå…­è¿›åˆ¶æ•°æ®
type ParsedHexData struct {
	BinaryData    []byte            `json:"binary_data"`
	OriginalSize  int               `json:"original_size"`
	MD5Hash       string            `json:"md5_hash"`
	IsValid       bool              `json:"is_valid"`
	Metadata      *utils.Metadata   `json:"metadata"`
	ParsedAt      time.Time         `json:"parsed_at"`
	ErrorMessage  string            `json:"error_message,omitempty"`
}

// NewHexDataAnalyzer åˆ›å»ºæ–°çš„åå…­è¿›åˆ¶æ•°æ®è§£æå™¨
func NewHexDataAnalyzer(record *utils.RawDataRecord) *HexDataAnalyzer {
	return &HexDataAnalyzer{
		rawDataRecord: record,
		logger:        utils.GetLogger(),
	}
}

// LoadFromFile ä»JSONæ–‡ä»¶åŠ è½½åŸå§‹æ•°æ®è®°å½•
func LoadHexDataFromFile(filePath string) (*HexDataAnalyzer, error) {
	record, err := utils.LoadRawDataForReplay(filePath)
	if err != nil {
		return nil, fmt.Errorf("åŠ è½½åŸå§‹æ•°æ®æ–‡ä»¶å¤±è´¥: %w", err)
	}
	
	return NewHexDataAnalyzer(record), nil
}

// ParseHexData è§£æåå…­è¿›åˆ¶æ•°æ®ä¸ºäºŒè¿›åˆ¶æµ
func (h *HexDataAnalyzer) ParseHexData() (*ParsedHexData, error) {
	h.logger.Debug("å¼€å§‹è§£æåå…­è¿›åˆ¶æ•°æ®",
		utils.Int("hex_length", len(h.rawDataRecord.HexData)),
		utils.String("original_md5", h.rawDataRecord.MD5Hash))

	// éªŒè¯è¾“å…¥æ•°æ®
	if h.rawDataRecord.HexData == "" {
		return &ParsedHexData{
			IsValid:      false,
			ErrorMessage: "åå…­è¿›åˆ¶æ•°æ®ä¸ºç©º",
			ParsedAt:     time.Now(),
		}, fmt.Errorf("åå…­è¿›åˆ¶æ•°æ®ä¸ºç©º")
	}

	// è§£ç åå…­è¿›åˆ¶å­—ç¬¦ä¸²
	binaryData, err := hex.DecodeString(h.rawDataRecord.HexData)
	if err != nil {
		return &ParsedHexData{
			IsValid:      false,
			ErrorMessage: fmt.Sprintf("åå…­è¿›åˆ¶è§£ç å¤±è´¥: %v", err),
			ParsedAt:     time.Now(),
		}, fmt.Errorf("åå…­è¿›åˆ¶è§£ç å¤±è´¥: %w", err)
	}

	// è®¡ç®—MD5æ ¡éªŒå’Œ
	actualMD5 := fmt.Sprintf("%x", md5.Sum(binaryData))
	
	// éªŒè¯æ•°æ®å®Œæ•´æ€§
	isValid := actualMD5 == h.rawDataRecord.MD5Hash
	
	result := &ParsedHexData{
		BinaryData:   binaryData,
		OriginalSize: len(binaryData),
		MD5Hash:      actualMD5,
		IsValid:      isValid,
		Metadata:     &h.rawDataRecord.Metadata,
		ParsedAt:     time.Now(),
	}

	if !isValid {
		result.ErrorMessage = fmt.Sprintf("MD5æ ¡éªŒå¤±è´¥: æœŸæœ›=%s, å®é™…=%s", 
			h.rawDataRecord.MD5Hash, actualMD5)
		h.logger.Warn("MD5æ ¡éªŒå¤±è´¥",
			utils.String("expected", h.rawDataRecord.MD5Hash),
			utils.String("actual", actualMD5))
	} else {
		h.logger.Debug("åå…­è¿›åˆ¶æ•°æ®è§£ææˆåŠŸ",
			utils.Int("binary_size", len(binaryData)),
			utils.String("md5_verified", actualMD5))
	}

	return result, nil
}

// ValidateIntegrity éªŒè¯æ•°æ®å®Œæ•´æ€§
func (h *HexDataAnalyzer) ValidateIntegrity() error {
	parsed, err := h.ParseHexData()
	if err != nil {
		return err
	}
	
	if !parsed.IsValid {
		return fmt.Errorf("æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: %s", parsed.ErrorMessage)
	}
	
	return nil
}

// GetMetadata è·å–å…ƒæ•°æ®ä¿¡æ¯
func (h *HexDataAnalyzer) GetMetadata() *utils.Metadata {
	return &h.rawDataRecord.Metadata
}

// EventStreamParser AWS Event Streamåè®®è§£æå™¨
type EventStreamParser struct {
	compliantParser *parser.CompliantEventStreamParser
	logger          utils.Logger
}

// ParsedEvent è§£æåçš„äº‹ä»¶
type ParsedEvent struct {
	EventType    string                 `json:"event_type"`
	Headers      map[string]interface{} `json:"headers"`
	Payload      interface{}            `json:"payload"`
	RawData      []byte                 `json:"raw_data"`
	ParsedAt     time.Time              `json:"parsed_at"`
	EventIndex   int                    `json:"event_index"`
	ByteOffset   int                    `json:"byte_offset"`
	ErrorMessage string                 `json:"error_message,omitempty"`
}

// ParseResult è§£æç»“æœ
type ParseResult struct {
	Events         []*ParsedEvent `json:"events"`
	TotalEvents    int            `json:"total_events"`
	TotalBytes     int            `json:"total_bytes"`
	ParsedAt       time.Time      `json:"parsed_at"`
	ParseDuration  time.Duration  `json:"parse_duration"`
	Success        bool           `json:"success"`
	ErrorMessage   string         `json:"error_message,omitempty"`
}

// NewEventStreamParser åˆ›å»ºæ–°çš„äº‹ä»¶æµè§£æå™¨
func NewEventStreamParser() *EventStreamParser {
	compliantParser := parser.GlobalCompliantParserPool.Get()
	
	return &EventStreamParser{
		compliantParser: compliantParser,
		logger:          utils.GetLogger(),
	}
}

// Close é‡Šæ”¾èµ„æº
func (p *EventStreamParser) Close() {
	if p.compliantParser != nil {
		parser.GlobalCompliantParserPool.Put(p.compliantParser)
		p.compliantParser = nil
	}
}

// ParseEventStream è§£æäº‹ä»¶æµæ•°æ®
func (p *EventStreamParser) ParseEventStream(data []byte) (*ParseResult, error) {
	startTime := time.Now()
	
	p.logger.Debug("å¼€å§‹è§£æAWS Event Stream",
		utils.Int("data_size", len(data)))

	result := &ParseResult{
		Events:    make([]*ParsedEvent, 0),
		ParsedAt:  startTime,
		Success:   false,
	}

	// ğŸ”§ ä¿®å¤: ä¸ä½¿ç”¨åˆ†å—ï¼Œç›´æ¥è§£æå®Œæ•´çš„äºŒè¿›åˆ¶æµ
	// AWS EventStreaméœ€è¦æŒ‰æ¶ˆæ¯è¾¹ç•Œå¤„ç†ï¼Œä¸èƒ½ä»»æ„åˆ†å—
	
	// ä½¿ç”¨ç¬¦åˆè§„èŒƒçš„è§£æå™¨è§£ææ•´ä¸ªæ•°æ®æµ
	events, parseErr := p.compliantParser.ParseStream(data)
	if parseErr != nil {
		p.logger.Warn("è§£æEventStreamæ—¶å‡ºç°é”™è¯¯",
			utils.Err(parseErr),
			utils.Int("data_size", len(data)))
		// åœ¨éä¸¥æ ¼æ¨¡å¼ä¸‹ç»§ç»­å¤„ç†
	}

	// å¤„ç†è§£æåˆ°çš„äº‹ä»¶
	eventIndex := 0
	for _, event := range events {
		parsedEvent, err := p.convertToStandardEvent(event, eventIndex, 0)
		if err != nil {
			p.logger.Warn("è½¬æ¢äº‹ä»¶æ ¼å¼å¤±è´¥",
				utils.Err(err),
				utils.Int("event_index", eventIndex))
			
			// åˆ›å»ºé”™è¯¯äº‹ä»¶è®°å½•
			parsedEvent = &ParsedEvent{
				EventType:    "parse_error",
				Headers:      make(map[string]interface{}),
				Payload:      nil,
				RawData:      data, // ä½¿ç”¨åŸå§‹æ•°æ®è€Œä¸æ˜¯é”™è¯¯çš„chunk
				ParsedAt:     time.Now(),
				EventIndex:   eventIndex,
				ByteOffset:   0,
				ErrorMessage: err.Error(),
			}
		}
		
		result.Events = append(result.Events, parsedEvent)
		eventIndex++
	}

	result.TotalEvents = len(result.Events)
	result.TotalBytes = len(data)
	result.ParseDuration = time.Since(startTime)
	result.Success = len(result.Events) > 0

	p.logger.Debug("Event Streamè§£æå®Œæˆ",
		utils.Int("total_events", result.TotalEvents),
		utils.Int("total_bytes", result.TotalBytes),
		utils.Duration("parse_duration", result.ParseDuration))

	return result, nil
}

// convertToStandardEvent è½¬æ¢ä¸ºæ ‡å‡†äº‹ä»¶æ ¼å¼
func (p *EventStreamParser) convertToStandardEvent(event parser.SSEEvent, index, offset int) (*ParsedEvent, error) {
	parsedEvent := &ParsedEvent{
		EventIndex: index,
		ByteOffset: offset,
		ParsedAt:   time.Now(),
		Headers:    make(map[string]interface{}),
	}

	// ç¡®å®šäº‹ä»¶ç±»å‹
	if event.Event != "" {
		parsedEvent.EventType = event.Event
	} else {
		parsedEvent.EventType = "unknown"
	}

	// å¤„ç†è½½è·æ•°æ®
	if event.Data != nil {
		parsedEvent.Payload = event.Data
		
		// å°è¯•æå–æ›´å¤šä¿¡æ¯
		if dataMap, ok := event.Data.(map[string]interface{}); ok {
			// æ£€æŸ¥æ˜¯å¦æ˜¯assistantResponseEvent
			if eventType, exists := dataMap["type"]; exists {
				if typeStr, ok := eventType.(string); ok {
					switch typeStr {
					case "content_block_start", "content_block_delta", "content_block_stop":
						parsedEvent.EventType = "assistantResponseEvent"
					case "message_start", "message_delta", "message_stop":
						parsedEvent.EventType = "assistantResponseEvent"
					}
				}
			}
			
			// æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯
			if contentBlock, exists := dataMap["content_block"]; exists {
				if cb, ok := contentBlock.(map[string]interface{}); ok {
					if cbType, exists := cb["type"]; exists && cbType == "tool_use" {
						parsedEvent.EventType = "toolUseEvent"
					}
				}
			}
		}
	}

	// åºåˆ—åŒ–åŸå§‹æ•°æ®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
	if rawBytes, err := json.Marshal(event); err == nil {
		parsedEvent.RawData = rawBytes
	}

	return parsedEvent, nil
}

// ValidateEventFormat éªŒè¯äº‹ä»¶æ ¼å¼
func (p *EventStreamParser) ValidateEventFormat(event *ParsedEvent) error {
	if event == nil {
		return fmt.Errorf("äº‹ä»¶ä¸ºç©º")
	}
	
	if event.EventType == "" {
		return fmt.Errorf("äº‹ä»¶ç±»å‹ä¸ºç©º")
	}
	
	// éªŒè¯å·²çŸ¥äº‹ä»¶ç±»å‹
	validEventTypes := map[string]bool{
		"assistantResponseEvent": true,
		"toolUseEvent":          true,
		"parse_error":           true,
		"unknown":               true,
	}
	
	if !validEventTypes[event.EventType] {
		return fmt.Errorf("æœªçŸ¥çš„äº‹ä»¶ç±»å‹: %s", event.EventType)
	}
	
	return nil
}

// GetEventSummary è·å–äº‹ä»¶æ‘˜è¦
func (p *EventStreamParser) GetEventSummary(result *ParseResult) map[string]int {
	summary := make(map[string]int)
	
	for _, event := range result.Events {
		summary[event.EventType]++
	}
	
	return summary
}

// BatchParseFiles æ‰¹é‡è§£æå¤šä¸ªæ–‡ä»¶
func BatchParseHexDataFiles(filePaths []string) ([]*ParseResult, error) {
	results := make([]*ParseResult, 0, len(filePaths))
	
	for _, filePath := range filePaths {
		// åŠ è½½hexæ•°æ®
		analyzer, err := LoadHexDataFromFile(filePath)
		if err != nil {
			return nil, fmt.Errorf("åŠ è½½æ–‡ä»¶ %s å¤±è´¥: %w", filePath, err)
		}
		
		// è§£æhexæ•°æ®
		hexData, err := analyzer.ParseHexData()
		if err != nil {
			return nil, fmt.Errorf("è§£æhexæ•°æ®å¤±è´¥ %s: %w", filePath, err)
		}
		
		if !hexData.IsValid {
			return nil, fmt.Errorf("æ–‡ä»¶ %s çš„hexæ•°æ®æ ¡éªŒå¤±è´¥: %s", filePath, hexData.ErrorMessage)
		}
		
		// è§£æäº‹ä»¶æµ
		parser := NewEventStreamParser()
		defer parser.Close()
		
		parseResult, err := parser.ParseEventStream(hexData.BinaryData)
		if err != nil {
			return nil, fmt.Errorf("è§£æäº‹ä»¶æµå¤±è´¥ %s: %w", filePath, err)
		}
		
		results = append(results, parseResult)
	}
	
	return results, nil
}